# üê≥ Im√°genes Docker Oficiales de Intel para PyTorch

## üìã Descripci√≥n

Intel ofrece dos im√°genes Docker oficiales optimizadas para PyTorch que pueden mejorar significativamente el rendimiento en hardware Intel (CPUs y GPUs Intel Arc):

1. **Intel¬Æ Extension for PyTorch** (`intel/intel-extension-for-pytorch`)
2. **Intel¬Æ Optimized PyTorch** (`intel/intel-optimized-pytorch`)

**Referencias**:
- [Intel Extension for PyTorch en Docker Hub](https://hub.docker.com/r/intel/intel-extension-for-pytorch)
- [Intel Optimized PyTorch en Docker Hub](https://hub.docker.com/r/intel/intel-optimized-pytorch)

## üéØ Diferencias entre las Im√°genes

### Intel¬Æ Extension for PyTorch
- **Incluye**: PyTorch + Intel Extension for PyTorch preinstalado
- **Soporte**: CPU y GPU Intel (incluyendo Intel Arc A750)
- **Optimizaciones**: 
  - AVX-512 y VNNI en CPUs
  - XMX en GPUs Intel Arc
  - Optimizaciones de kernel espec√≠ficas para Intel
- **Ideal para**: Usuarios que quieren aprovechar GPUs Intel Arc o CPUs Intel de √∫ltima generaci√≥n

### Intel¬Æ Optimized PyTorch
- **Incluye**: PyTorch optimizado para hardware Intel
- **Soporte**: Principalmente CPU (optimizaciones AVX-512, VNNI)
- **Optimizaciones**: Optimizaciones de compilaci√≥n y runtime para CPUs Intel
- **Ideal para**: Usuarios que quieren mejor rendimiento en CPU sin necesidad de GPU

## üöÄ Uso en el Proyecto

### Opci√≥n 1: Usar Dockerfile Basado en Intel Extension (Recomendado para GPU)

Hemos creado un Dockerfile alternativo que usa la imagen oficial de Intel Extension for PyTorch:

```bash
# Construir con Intel Extension
docker build -f docker/Dockerfile.backend.intel -t p2p-backend-intel ./backend

# O usar docker-compose
docker-compose -f docker-compose.yml -f docker-compose.intel.yml up -d backend
```

**Ventajas**:
- ‚úÖ PyTorch e Intel Extension preinstalados
- ‚úÖ Optimizaciones autom√°ticas para CPU y GPU Intel
- ‚úÖ Soporte para Intel Arc A750 (si est√° disponible)
- ‚úÖ Menos problemas de compatibilidad

### Opci√≥n 2: Usar Dockerfile Basado en Intel Optimized PyTorch (Solo CPU)

Para optimizaci√≥n solo en CPU:

```bash
# Construir con Intel Optimized PyTorch
docker build -f docker/Dockerfile.backend.intel-optimized -t p2p-backend-intel-cpu ./backend
```

**Ventajas**:
- ‚úÖ PyTorch optimizado para CPU Intel
- ‚úÖ Mejor rendimiento en CPUs Intel sin GPU
- ‚úÖ Imagen m√°s ligera

## üìä Comparaci√≥n de Rendimiento

### Con Intel Extension for PyTorch (GPU Intel Arc)
- **Entrenamiento**: 5-10x m√°s r√°pido que CPU (dependiendo del modelo)
- **Inferencia**: 3-5x m√°s r√°pido que CPU
- **Memoria**: Mejor gesti√≥n de memoria GPU

### Con Intel Optimized PyTorch (CPU)
- **Entrenamiento**: 20-30% m√°s r√°pido que PyTorch est√°ndar
- **Inferencia**: 15-25% m√°s r√°pido que PyTorch est√°ndar
- **Memoria**: Optimizaciones de memoria para CPUs Intel

## üîß Configuraci√≥n

### Variables de Entorno

Para Intel Extension for PyTorch:

```bash
# Habilitar XPU (GPU Intel)
USE_XPU=1
ZE_FLAT_DEVICE_HIERARCHY=COMPOSITE

# Configurar Intel Extension
INTEL_EXTENSION_FOR_PYTORCH_SKIP_BINDING=0
```

### Docker Compose

Hemos creado `docker-compose.intel.yml` que usa las im√°genes de Intel:

```yaml
services:
  backend:
    build:
      context: ./backend
      dockerfile: ../docker/Dockerfile.backend.intel
    environment:
      - USE_XPU=1
      - INTEL_EXTENSION_FOR_PYTORCH_SKIP_BINDING=0
    devices:
      - /dev/dri:/dev/dri  # Para acceso a GPU
```

## üéØ Cu√°ndo Usar Cada Imagen

### Usa Intel Extension for PyTorch si:
- ‚úÖ Tienes GPU Intel Arc A750 (o otra GPU Intel)
- ‚úÖ Quieres el mejor rendimiento posible
- ‚úÖ Necesitas soporte para CPU y GPU
- ‚úÖ Est√°s entrenando modelos grandes

### Usa Intel Optimized PyTorch si:
- ‚úÖ Solo tienes CPU Intel (sin GPU)
- ‚úÖ Quieres mejor rendimiento en CPU
- ‚úÖ No necesitas soporte GPU
- ‚úÖ Quieres una imagen m√°s ligera

### Usa el Dockerfile Original si:
- ‚úÖ No tienes hardware Intel espec√≠fico
- ‚úÖ Quieres m√°xima compatibilidad
- ‚úÖ No necesitas optimizaciones espec√≠ficas de Intel

## üîç Verificaci√≥n

### Verificar que Intel Extension est√° funcionando

```bash
# Entrar al contenedor
docker exec -it p2p_backend_intel python

# En Python
import torch
import intel_extension_for_pytorch as ipex

print(f"PyTorch version: {torch.__version__}")
print(f"Intel Extension available: {ipex.__version__}")

# Verificar GPU
if hasattr(torch, 'xpu') and torch.xpu.is_available():
    print(f"GPU available: {torch.xpu.get_device_name(0)}")
else:
    print("GPU not available, using CPU")
```

### Verificar rendimiento

```bash
# Probar endpoint de GPU status
curl http://localhost:8000/api/v1/analytics/gpu/status

# Ver logs del contenedor
docker logs p2p_backend_intel | grep -i "intel\|gpu\|xpu"
```

## ‚ö†Ô∏è Limitaciones

### Docker Desktop Windows
- **Acceso a GPU**: Puede no funcionar correctamente en Docker Desktop Windows
- **Soluci√≥n**: Usar WSL2 o ejecutar directamente en Windows

### Compatibilidad
- **Solo Intel**: Estas optimizaciones est√°n dise√±adas espec√≠ficamente para hardware Intel
- **AMD/ARM**: No se beneficiar√°n de estas optimizaciones

### Tama√±o de Imagen
- **Intel Extension**: Imagen m√°s grande (~2-3GB)
- **Intel Optimized**: Imagen mediana (~1-2GB)
- **Original**: Imagen m√°s peque√±a (~500MB-1GB)

## üöÄ Migraci√≥n

### Desde Dockerfile Original

1. **Backup**: Guarda tu `docker-compose.yml` actual
2. **Prueba**: Usa `docker-compose.intel.yml` para probar
3. **Verifica**: Aseg√∫rate de que todo funciona correctamente
4. **Reemplaza**: Si todo est√° bien, puedes reemplazar el Dockerfile original

```bash
# Probar con Intel Extension
docker-compose -f docker-compose.yml -f docker-compose.intel.yml up -d backend

# Verificar que funciona
curl http://localhost:8000/api/v1/health
curl http://localhost:8000/api/v1/analytics/gpu/status

# Si funciona bien, puedes hacer el cambio permanente
```

## üìö Referencias

- [Intel Extension for PyTorch - Docker Hub](https://hub.docker.com/r/intel/intel-extension-for-pytorch)
- [Intel Optimized PyTorch - Docker Hub](https://hub.docker.com/r/intel/intel-optimized-pytorch)
- [Intel Extension for PyTorch - Documentaci√≥n](https://intel.github.io/intel-extension-for-pytorch/)
- [Intel Optimized PyTorch - GitHub](https://github.com/intel/intel-extension-for-pytorch)

## üéØ Recomendaciones

1. **Para Desarrollo**: Usa el Dockerfile original (m√°s r√°pido de construir, suficiente para desarrollo)

2. **Para Producci√≥n con GPU Intel**: Usa `Dockerfile.backend.intel` (mejor rendimiento con GPU)

3. **Para Producci√≥n solo CPU Intel**: Usa `Dockerfile.backend.intel-optimized` (mejor rendimiento en CPU)

4. **Para Testing**: Prueba ambas opciones y mide el rendimiento en tu hardware espec√≠fico

## üîç Troubleshooting

### Error: "Intel Extension not found"
```bash
# Verificar que la imagen se construy√≥ correctamente
docker images | grep intel

# Reconstruir la imagen
docker-compose -f docker-compose.intel.yml build --no-cache backend
```

### Error: "GPU not available"
```bash
# Verificar acceso a dispositivos GPU
docker exec p2p_backend_intel ls -la /dev/dri/

# Verificar drivers en el host
lspci | grep -i intel
```

### Error: "Import error"
```bash
# Verificar que PyTorch est√° instalado correctamente
docker exec p2p_backend_intel python -c "import torch; print(torch.__version__)"

# Verificar Intel Extension
docker exec p2p_backend_intel python -c "import intel_extension_for_pytorch as ipex; print(ipex.__version__)"
```

