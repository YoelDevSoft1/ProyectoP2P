# 游냡 Gu칤a R치pida: Im치genes Docker de Intel para PyTorch

## 游 Inicio R치pido

### Opci칩n 1: Intel Extension for PyTorch (GPU + CPU)

```bash
# Usar im치genes oficiales de Intel con soporte GPU
docker-compose -f docker-compose.yml -f docker-compose.intel.yml up -d backend

# Verificar
curl http://localhost:8000/api/v1/analytics/gpu/status
```

### Opci칩n 2: Intel Optimized PyTorch (Solo CPU)

```bash
# Modificar docker-compose.intel.yml para usar Dockerfile.backend.intel-optimized
# Luego ejecutar
docker-compose -f docker-compose.yml -f docker-compose.intel.yml up -d backend
```

## 游늵 쮺u치l usar?

| Si tienes... | Usa... | Ventaja |
|--------------|--------|---------|
| GPU Intel Arc A750 | `Dockerfile.backend.intel` | 5-10x m치s r치pido en GPU |
| CPU Intel (sin GPU) | `Dockerfile.backend.intel-optimized` | 20-30% m치s r치pido en CPU |
| Cualquier hardware | `Dockerfile.backend` (original) | M치xima compatibilidad |

## 游댌 Verificar Instalaci칩n

```bash
# Verificar PyTorch e Intel Extension
docker exec -it p2p_backend_intel python -c "import torch; import intel_extension_for_pytorch as ipex; print(f'PyTorch: {torch.__version__}, Intel Extension: {ipex.__version__}')"

# Verificar GPU
docker exec -it p2p_backend_intel python -c "import torch; print('GPU disponible' if hasattr(torch, 'xpu') and torch.xpu.is_available() else 'Usando CPU')"
```

## 游닄 Documentaci칩n Completa

- [Documentaci칩n detallada](docs/INTEL_DOCKER_IMAGES.md)
- [Resumen de implementaci칩n](RESUMEN_INTEL_DOCKER_IMAGES.md)

## 游댕 Referencias

- [Intel Extension for PyTorch - Docker Hub](https://hub.docker.com/r/intel/intel-extension-for-pytorch)
- [Intel Optimized PyTorch - Docker Hub](https://hub.docker.com/r/intel/intel-optimized-pytorch)

