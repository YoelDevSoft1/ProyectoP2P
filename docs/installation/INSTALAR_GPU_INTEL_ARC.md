# ğŸ® GuÃ­a: Instalar GPU Intel Arc A750 en tu Proyecto

## ğŸ“‹ Resumen

Tu GPU Intel Arc A750 estÃ¡ instalada y funcionando en Windows. Para usarla en tu proyecto P2P Trading, tienes **2 opciones**:

### OpciÃ³n 1: Instalar en Windows (Recomendado para GPU) âœ…

**Ventajas**:
- âœ… MÃ¡ximo rendimiento de GPU
- âœ… Acceso directo a drivers
- âœ… Sin limitaciones de Docker
- âœ… GPU funciona correctamente

**Desventajas**:
- Requiere Python instalado en Windows
- Separado del entorno Docker

### OpciÃ³n 2: Usar CPU en Docker (Recomendado para Simplicidad) âœ…

**Ventajas**:
- âœ… Ya estÃ¡ funcionando
- âœ… Integrado con tu proyecto Docker
- âœ… No requiere configuraciÃ³n adicional
- âœ… Rendimiento suficiente para tus necesidades

**Desventajas**:
- GPU no disponible en Docker Desktop Windows
- Entrenamiento mÃ¡s lento (pero aceptable)

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Instalar GPU en Windows

```powershell
# Ejecutar script de instalaciÃ³n
.\scripts\instalar-gpu-windows.ps1
```

Este script:
1. âœ… Verifica que tu GPU Intel Arc A750 estÃ© reconocida
2. âœ… Instala PyTorch
3. âœ… Instala Intel Extension con soporte XPU (GPU)
4. âœ… Instala OpenVINO
5. âœ… Verifica que GPU estÃ© disponible

### OpciÃ³n 2: Usar CPU en Docker (Ya Configurado)

Tu sistema ya estÃ¡ configurado para usar CPU. El cÃ³digo detectarÃ¡ automÃ¡ticamente si hay GPU disponible y la usarÃ¡ si estÃ¡, o usarÃ¡ CPU si no estÃ¡.

## ğŸ”§ Verificar InstalaciÃ³n

### Verificar GPU en Windows

```powershell
python -c "from app.ml.gpu_utils import print_gpu_status; print_gpu_status()"
```

### Verificar GPU en Docker

```powershell
docker exec p2p_backend python -c "from app.ml.gpu_utils import print_gpu_status; print_gpu_status()"
```

## ğŸ’» Usar GPU en tu CÃ³digo

El mÃ³dulo `gpu_utils.py` detecta automÃ¡ticamente si hay GPU disponible:

```python
from app.ml.gpu_utils import get_device, to_device, optimize_model_for_inference

# Obtener dispositivo (GPU o CPU)
device = get_device()  # Detecta automÃ¡ticamente

# Mover modelo a GPU
model = model.to(device)

# O usar funciÃ³n helper
model = to_device(model)

# Optimizar para inferencia (usa Intel Extension si estÃ¡ disponible)
model = optimize_model_for_inference(model)
```

## ğŸ“Š ComparaciÃ³n de Opciones

| CaracterÃ­stica | Windows (GPU) | Docker (CPU) |
|----------------|---------------|--------------|
| Rendimiento GPU | âœ… Alto | âŒ No disponible |
| Facilidad | âš ï¸ Media | âœ… Alta |
| IntegraciÃ³n | âš ï¸ Separado | âœ… Integrado |
| Entrenamiento | âœ… RÃ¡pido (GPU) | âš ï¸ Lento (CPU) |
| Inferencia | âœ… Muy rÃ¡pido | âœ… RÃ¡pido (<100ms) |
| Recomendado para | Entrenamiento frecuente | ProducciÃ³n/Desarrollo |

## ğŸ¯ RecomendaciÃ³n

### Para Desarrollo/ProducciÃ³n: Usar CPU en Docker âœ…

**Razones**:
- âœ… Ya estÃ¡ funcionando
- âœ… Integrado con tu proyecto
- âœ… Rendimiento suficiente para inferencia (<100ms)
- âœ… Entrenamiento aceptable (5-15 minutos)

### Para MÃ¡ximo Rendimiento: Instalar en Windows âœ…

**CuÃ¡ndo usar**:
- Entrenas modelos muy grandes frecuentemente
- Necesitas mÃ¡ximo rendimiento de GPU
- Tienes tiempo para configurar

## ğŸ” Troubleshooting

### GPU no se reconoce

1. **Verificar drivers**:
   ```powershell
   Get-PnpDevice | Where-Object {$_.FriendlyName -like "*Arc*"}
   ```

2. **Actualizar drivers**:
   - Descarga desde: https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html
   - Instala y reinicia el sistema

3. **Verificar en Administrador de dispositivos**:
   - Busca "Adaptadores de pantalla"
   - Debe aparecer "Intel Arc A750"

### Intel Extension no funciona en Docker

**Esto es normal**. Docker Desktop en Windows tiene limitaciones para GPU Intel. 

**SoluciÃ³n**: Usar CPU (funciona perfectamente) o instalar en Windows.

### GPU disponible pero no se usa

1. Verifica que Intel Extension estÃ© instalado:
   ```powershell
   python -c "import intel_extension_for_pytorch as ipex; print('OK')"
   ```

2. Verifica que GPU estÃ© disponible:
   ```powershell
   python -c "import torch; print('GPU:', torch.xpu.is_available() if hasattr(torch, 'xpu') else False)"
   ```

## âœ… Estado Actual

Tu sistema estÃ¡ configurado para:
- âœ… Detectar automÃ¡ticamente GPU si estÃ¡ disponible
- âœ… Usar GPU si estÃ¡ disponible
- âœ… Usar CPU si GPU no estÃ¡ disponible (funciona perfectamente)
- âœ… Optimizar modelos para inferencia

## ğŸ“š Referencias

- [Intel Arc Drivers](https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html)
- [Intel Extension for PyTorch](https://github.com/intel/intel-extension-for-pytorch)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)

## ğŸ‰ ConclusiÃ³n

**Tu sistema estÃ¡ listo para usar GPU cuando estÃ© disponible**. 

- Si instalas en Windows: GPU funcionarÃ¡ con mÃ¡ximo rendimiento
- Si usas Docker: CPU funcionarÃ¡ perfectamente para tus necesidades

**El cÃ³digo detecta automÃ¡ticamente la mejor opciÃ³n disponible**. ğŸš€

